# Отток клиентов

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

Построить модель с предельно большим значением F1-меры. По заданию, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.

Дополнительно измерить AUC-ROC, сравнивая её значение с F1-мерой.

Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)
Признаки

- `RowNumber` — индекс строки в данных
- `CustomerId` — уникальный идентификатор клиента
- `Surname` — фамилия
- `CreditScore` — кредитный рейтинг
- `Geography` — страна проживания
- `Gender` — пол
- `Age` — возраст
- `Tenure` — сколько лет человек является клиентом банка
- `Balance` — баланс на счёте
- `NumOfProducts` — количество продуктов банка, используемых клиентом
- `HasCrCard` — наличие кредитной карты
- `IsActiveMember` — активность клиента
- `EstimatedSalary` — предполагаемая зарплата

Целевой признак

- `Exited` — факт ухода клиента

Задачей проекта было научиться проверять баланс классов и научиться работать с дисбалансом для улучшения предсказаний моделей.

При исследовании дисбаланса и работы по увеличению точности предсказаний были использованы ML модели:
DecisionTreeClassifier
RandomForestClassifier
LogisticRegression

- При первичном исследовании датасета были обнаружены пустые значения и аномалии.
- Был проведен тест предсказаний моделей при варианте удаления этих строк и потере 12% данных.Следующий шаг для эксперимента было принято решение данные не удалять, а заменить пустые и нулевые значения на 1.Это показало положительную динамику для повышения мерки F1.
- Перед исследованием данные были переведены в числовые, там где это было необходимо.Количественные признаки были масштабированы.
- Колонки которые не несли в себе общих признаков были удалены.
- Было проведено исследование матриц ошибок где наблюдался дисбаланс классов.
- Были исследованы модели без учета дисбаланса.Лучшая метрика была у RandomForestClassifier Деревьев: 9 Accuracy: 0.856 F1: 0.5943661971830986.
- В дальнейшем были исследованы 4 вида борьбы с дисбалансом классов:
- - Взвешивание классов(применение аргумента class_weight ='balanced')
- - Увеличение положительных ответов в выборке
- - Снижение отрицательных ответов в выборке
- - Изменение порога.
- Лучший показатель дал метод изменения порога у двух моделей RandomForestClassifier и DecisionTreeClassifier
По итогу для теста была выбрана модель DecisionTreeClassifier